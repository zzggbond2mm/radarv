#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XGBoost è¶…å‚æ•°è°ƒä¼˜è„šæœ¬ (ä½¿ç”¨ç½‘æ ¼æœç´¢)
"""

import os
import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.model_selection import GridSearchCV, train_test_split
from datetime import datetime

# å¯¼å…¥æ•°æ®å¤„ç†å’ŒGPUæ£€æµ‹é€»è¾‘
from train_classifier import prepare_dataset, check_gpu_availability, NEGATIVE_TO_POSITIVE_RATIO

def run_grid_search():
    """æ‰§è¡Œç½‘æ ¼æœç´¢è°ƒä¼˜"""
    print("="*60)
    print("ğŸš€ å¼€å§‹ XGBoost è¶…å‚æ•°ç½‘æ ¼æœç´¢ ğŸš€")
    print("="*60)

    # --- 1. åŠ è½½å’Œå‡†å¤‡æ•°æ® ---
    # æˆ‘ä»¬ä½¿ç”¨ä¸ä¸»è®­ç»ƒè„šæœ¬ç›¸åŒçš„é€»è¾‘æ¥ä¿è¯æ•°æ®ä¸€è‡´æ€§
    # æ³¨æ„ï¼šè¿™é‡Œä¼šåŠ è½½å®Œæ•´æ•°æ®é›†è¿›è¡Œäº¤å‰éªŒè¯
    dataset = prepare_dataset()
    if dataset is None or dataset.empty:
        print("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼Œè°ƒä¼˜ä¸­æ­¢ã€‚")
        return

    X = dataset.drop('label', axis=1)
    y = dataset['label']
    
    print(f"\næ•°æ®å‡†å¤‡å®Œæˆï¼Œå…± {len(dataset)} æ¡æ•°æ®ç”¨äºè°ƒä¼˜ã€‚")

    # --- 2. å®šä¹‰å‚æ•°ç½‘æ ¼ ---
    # åœ¨è¿™é‡Œå®šä¹‰æ‚¨æƒ³æµ‹è¯•çš„å‚æ•°å€¼
    # æ³¨æ„ï¼šç»„åˆè¶Šå¤šï¼Œæœç´¢æ—¶é—´è¶Šé•¿
    param_grid = {
        'max_depth': [10, 12, 14],
        'n_estimators': [600, 800, 1000, 1200, 1400]
    }
    
    print("\n--- å®šä¹‰æœç´¢å‚æ•°ç½‘æ ¼ ---")
    for key, value in param_grid.items():
        print(f"  - {key}: {value}")
        
    n_combinations = np.prod([len(v) for v in param_grid.values()])
    cv_folds = 3
    total_fits = n_combinations * cv_folds
    print(f"æ€»å…±å°†æµ‹è¯• {n_combinations} ç§å‚æ•°ç»„åˆã€‚")
    print(f"ä½¿ç”¨ {cv_folds} æŠ˜äº¤å‰éªŒè¯ï¼Œæ€»å…±éœ€è¦è¿›è¡Œ {total_fits} æ¬¡æ¨¡å‹è®­ç»ƒã€‚")

    # --- 3. é…ç½®XGBoostæ¨¡å‹å’ŒGridSearchCV ---
    use_gpu = check_gpu_availability()
    
    # è®¡ç®—ç±»åˆ«æƒé‡
    scale_pos_weight = (y == 0).sum() / (y == 1).sum()
    print(f"\nè®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡ (scale_pos_weight): {scale_pos_weight:.2f}")

    # åˆå§‹åŒ–XGBooståˆ†ç±»å™¨
    xgb_estimator = xgb.XGBClassifier(
        objective='binary:logistic',
        eval_metric='logloss',
        device='cuda' if use_gpu else 'cpu',
        tree_method='hist',
        scale_pos_weight=scale_pos_weight,
        random_state=42
    )

    # é…ç½®GridSearchCV
    # cv=3 è¡¨ç¤º3æŠ˜äº¤å‰éªŒè¯ï¼Œæ›´å¯é 
    # scoring='f1' è¡¨ç¤ºæˆ‘ä»¬ä¼˜åŒ–çš„ç›®æ ‡æ˜¯F1åˆ†æ•°
    # verbose=3 æä¾›è¯¦ç»†çš„è¿›åº¦è¾“å‡ºï¼Œæ‚¨ä¼šçœ‹åˆ° [CV 1/3]... è¿™æ ·çš„å®æ—¶æ—¥å¿—
    # n_jobs=-1 ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒå¹¶è¡Œå¤„ç†
    grid_search = GridSearchCV(
        estimator=xgb_estimator,
        param_grid=param_grid,
        scoring='f1',
        cv=cv_folds,
        verbose=3,
        n_jobs=-1
    )

    print("\n--- å¼€å§‹æ‰§è¡Œç½‘æ ¼æœç´¢ ---")
    print("è¿™å°†éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå…·ä½“å–å†³äºæ‚¨çš„æ•°æ®é‡å’ŒCPU/GPUæ€§èƒ½...")
    print(f"è¯¦ç»†çš„è®­ç»ƒè¿›åº¦ (å…± {total_fits} æ¡) å°†ä¼šå®æ—¶æ‰“å°åœ¨ä¸‹æ–¹ï¼Œè¯·ä¿æŒè€å¿ƒã€‚")
    
    start_time = datetime.now()
    grid_search.fit(X, y)
    end_time = datetime.now()
    
    print(f"\nâœ… ç½‘æ ¼æœç´¢å®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time}")

    # --- 4. è¾“å‡ºå¹¶ä¿å­˜ç»“æœ ---
    results_df = pd.DataFrame(grid_search.cv_results_)
    results_df = results_df.sort_values(by='rank_test_score')

    log_filename = "tuning_results_log.txt"
    with open(log_filename, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write(f"      XGBoost å‚æ•°è°ƒä¼˜ç»“æœ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
        f.write("="*60 + "\n\n")

        f.write("--- æœ€ä½³F1åˆ†æ•° ---\n")
        f.write(f"{grid_search.best_score_:.4f}\n\n")

        f.write("--- æœ€ä½³å‚æ•°ç»„åˆ ---\n")
        for param, value in grid_search.best_params_.items():
            f.write(f"  - {param}: {value}\n")
        f.write("\n")

        f.write("--- è¯¦ç»†äº¤å‰éªŒè¯ç»“æœ ---\n")
        f.write(results_df[['rank_test_score', 'mean_test_score', 'std_test_score', 'params']].to_string())
        f.write("\n\n")
        f.write("="*60 + "\n")
        f.write("æç¤º: è¯·å°†æ‰¾åˆ°çš„æœ€ä½³å‚æ•°ç»„åˆæ›´æ–°åˆ° train_classifier.py ä¸­ã€‚\n")
        f.write("="*60 + "\n")

    print("\n" + "="*25 + " è°ƒä¼˜ç»“æœæ€»ç»“ " + "="*25)
    print(f"ğŸ† æœ€ä½³F1åˆ†æ•°: {grid_search.best_score_:.4f}")
    print("ğŸ† æœ€ä½³å‚æ•°ç»„åˆ:")
    for param, value in grid_search.best_params_.items():
        print(f"   - {param}: {value}")
    
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶: '{log_filename}'")
    print("\nè¯·æ ¹æ®æ—¥å¿—æ–‡ä»¶ä¸­çš„'æœ€ä½³å‚æ•°ç»„åˆ'ï¼Œæ‰‹åŠ¨æ›´æ–° 'train_classifier.py' ä¸­çš„é»˜è®¤å‚æ•°ã€‚")
    print("="*70)

if __name__ == '__main__':
    run_grid_search() 