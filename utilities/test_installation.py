#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰è£…éªŒè¯æµ‹è¯•è„šæœ¬
å¿«é€Ÿæ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
"""

import sys
import platform
import subprocess

def print_separator(title):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print("\n" + "="*60)
    print(f"ğŸ” {title}")
    print("="*60)

def check_python_environment():
    """æ£€æŸ¥Pythonç¯å¢ƒ"""
    print_separator("Pythonç¯å¢ƒä¿¡æ¯")
    
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"Pythonå¯æ‰§è¡Œæ–‡ä»¶: {sys.executable}")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"æ¶æ„: {platform.architecture()}")
    
    try:
        import site
        site_packages = site.getsitepackages()
        if site_packages:
            print(f"åŒ…å®‰è£…ç›®å½•: {site_packages[0]}")
        user_site = site.getusersitepackages()
        print(f"ç”¨æˆ·åŒ…ç›®å½•: {user_site}")
    except:
        print("æ— æ³•è·å–åŒ…å®‰è£…è·¯å¾„")

def check_package_installation():
    """æ£€æŸ¥åŒ…å®‰è£…æƒ…å†µ"""
    print_separator("åŒ…å®‰è£…æ£€æŸ¥")
    
    required_packages = [
        ('pandas', 'æ•°æ®å¤„ç†'),
        ('numpy', 'æ•°å€¼è®¡ç®—'),
        ('scikit-learn', 'æœºå™¨å­¦ä¹ '),
        ('joblib', 'æ¨¡å‹åºåˆ—åŒ–'),
        ('xgboost', 'XGBoostæ ¸å¿ƒåº“'),
        ('GPUtil', 'GPUæ£€æµ‹å·¥å…·')
    ]
    
    optional_packages = [
        ('torch', 'PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶'),
        ('torchvision', 'PyTorchè§†è§‰åº“'),
        ('torchaudio', 'PyTorchéŸ³é¢‘åº“')
    ]
    
    def check_package_list(packages, category):
        print(f"\nğŸ“¦ {category}:")
        for package, description in packages:
            try:
                result = subprocess.run(
                    f"pip show {package}", 
                    shell=True, 
                    capture_output=True, 
                    text=True
                )
                if result.returncode == 0:
                    lines = result.stdout.split('\n')
                    version = next((line.split(':')[1].strip() for line in lines if 'Version:' in line), "æœªçŸ¥")
                    location = next((line.split(':')[1].strip() for line in lines if 'Location:' in line), "æœªçŸ¥")
                    print(f"   âœ… {package:<15} v{version:<12} - {description}")
                    print(f"      ğŸ“ {location}")
                else:
                    print(f"   âŒ {package:<15} {'æœªå®‰è£…':<12} - {description}")
            except Exception as e:
                print(f"   âš ï¸  {package:<15} {'æ£€æŸ¥å¤±è´¥':<12} - {e}")
    
    check_package_list(required_packages, "å¿…éœ€åŒ…")
    check_package_list(optional_packages, "å¯é€‰åŒ…")

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print_separator("GPUç¯å¢ƒæ£€æŸ¥")
    
    # æ£€æŸ¥NVIDIA GPU
    try:
        result = subprocess.run("nvidia-smi", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA GPUæ£€æµ‹:")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'CUDA Version:' in line:
                    cuda_version = line.split('CUDA Version:')[1].strip().split()[0]
                    print(f"   ğŸ”§ CUDAç‰ˆæœ¬: {cuda_version}")
                elif 'NVIDIA GeForce' in line or 'Tesla' in line or 'Quadro' in line:
                    gpu_info = line.split('|')[1].strip()
                    print(f"   ğŸ® GPU: {gpu_info}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨")
    except:
        print("âŒ æ— æ³•è¿è¡Œnvidia-smiå‘½ä»¤")
    
    # æ£€æŸ¥GPUtil
    try:
        import GPUtil
        gpus = GPUtil.getGPUs()
        if gpus:
            print(f"\nâœ… GPUtilæ£€æµ‹åˆ° {len(gpus)} ä¸ªGPU:")
            for i, gpu in enumerate(gpus):
                print(f"   GPU {i}: {gpu.name}")
                print(f"     æ˜¾å­˜: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB")
                print(f"     ä½¿ç”¨ç‡: {gpu.load*100:.1f}%")
        else:
            print("\nâš ï¸  GPUtilæœªæ£€æµ‹åˆ°GPU")
    except ImportError:
        print("\nâŒ GPUtilæœªå®‰è£…")
    except Exception as e:
        print(f"\nâš ï¸  GPUtilæ£€æµ‹å¤±è´¥: {e}")

def check_xgboost():
    """æ£€æŸ¥XGBoost"""
    print_separator("XGBoostæ£€æŸ¥")
    
    try:
        import xgboost as xgb
        print(f"âœ… XGBoostç‰ˆæœ¬: {xgb.__version__}")
        
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        print("\nğŸ§ª åŸºæœ¬åŠŸèƒ½æµ‹è¯•:")
        from sklearn.datasets import make_classification
        from sklearn.model_selection import train_test_split
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        X, y = make_classification(n_samples=1000, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # CPUæµ‹è¯•
        print("   ğŸ–¥ï¸  CPUè®­ç»ƒæµ‹è¯•...")
        cpu_model = xgb.XGBClassifier(tree_method='hist', n_estimators=10)
        cpu_model.fit(X_train, y_train)
        cpu_score = cpu_model.score(X_test, y_test)
        print(f"      CPUæ¨¡å‹å‡†ç¡®ç‡: {cpu_score:.3f}")
        
        # GPUæµ‹è¯•
        print("   ğŸš€ GPUè®­ç»ƒæµ‹è¯•...")
        try:
            gpu_model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, n_estimators=10)
            gpu_model.fit(X_train, y_train)
            gpu_score = gpu_model.score(X_test, y_test)
            print(f"      âœ… GPUæ¨¡å‹å‡†ç¡®ç‡: {gpu_score:.3f}")
            print("      âœ… GPUè®­ç»ƒåŠŸèƒ½æ­£å¸¸")
        except Exception as e:
            print(f"      âš ï¸  GPUè®­ç»ƒå¤±è´¥: {e}")
            print("      ğŸ’¡ è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå–å†³äºGPUç¯å¢ƒ")
            
    except ImportError:
        print("âŒ XGBoostæœªå®‰è£…")
    except Exception as e:
        print(f"âŒ XGBoostæµ‹è¯•å¤±è´¥: {e}")

def check_pytorch():
    """æ£€æŸ¥PyTorch"""
    print_separator("PyTorchæ£€æŸ¥")
    
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"âœ… GPUè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
                
            # ç®€å•GPUæµ‹è¯•
            print("\nğŸ§ª GPUåŠŸèƒ½æµ‹è¯•:")
            try:
                x = torch.randn(1000, 1000).cuda()
                y = torch.randn(1000, 1000).cuda()
                z = torch.mm(x, y)
                print("   âœ… GPUçŸ©é˜µè¿ç®—æ­£å¸¸")
            except Exception as e:
                print(f"   âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä»…æ”¯æŒCPUè¿ç®—")
            
    except ImportError:
        print("âš ï¸  PyTorchæœªå®‰è£…ï¼ˆå¯é€‰ç»„ä»¶ï¼‰")
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")

def check_compatibility():
    """æ£€æŸ¥å…¼å®¹æ€§"""
    print_separator("å…¼å®¹æ€§æ£€æŸ¥")
    
    issues = []
    recommendations = []
    
    # æ£€æŸ¥CUDAå…¼å®¹æ€§
    try:
        result = subprocess.run("nvidia-smi", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            import re
            cuda_match = re.search(r'CUDA Version: (\d+\.\d+)', result.stdout)
            if cuda_match:
                cuda_version = float(cuda_match.group(1))
                
                try:
                    import torch
                    torch_cuda = torch.version.cuda
                    if torch_cuda:
                        torch_cuda_version = float(torch_cuda)
                        if cuda_version >= 12.0 and torch_cuda_version < 12.0:
                            issues.append(f"CUDAç‰ˆæœ¬({cuda_version})ä¸PyTorch CUDAç‰ˆæœ¬({torch_cuda})ä¸åŒ¹é…")
                            recommendations.append("å»ºè®®ä½¿ç”¨cu121ç‰ˆæœ¬çš„PyTorch")
                        elif cuda_version < 11.0:
                            issues.append(f"CUDAç‰ˆæœ¬è¿‡ä½({cuda_version})")
                            recommendations.append("å»ºè®®å‡çº§CUDAåˆ°11.8æˆ–æ›´é«˜ç‰ˆæœ¬")
                except ImportError:
                    pass
    except:
        pass
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬å…¼å®¹æ€§
    python_version = sys.version_info
    if python_version < (3, 7):
        issues.append(f"Pythonç‰ˆæœ¬è¿‡ä½({python_version.major}.{python_version.minor})")
        recommendations.append("å»ºè®®å‡çº§åˆ°Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
    elif python_version >= (3, 12):
        issues.append(f"Pythonç‰ˆæœ¬è¿‡é«˜({python_version.major}.{python_version.minor})")
        recommendations.append("æŸäº›åŒ…å¯èƒ½ä¸å…¼å®¹ï¼Œå»ºè®®ä½¿ç”¨Python 3.9-3.11")
    
    if issues:
        print("âš ï¸  å‘ç°æ½œåœ¨é—®é¢˜:")
        for issue in issues:
            print(f"   - {issue}")
        print("\nğŸ’¡ å»ºè®®:")
        for rec in recommendations:
            print(f"   - {rec}")
    else:
        print("âœ… æœªå‘ç°å…¼å®¹æ€§é—®é¢˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª å®‰è£…éªŒè¯æµ‹è¯•")
    print(f"è¿è¡Œæ—¶é—´: {platform.uname().node} - {sys.version.split()[0]}")
    
    check_python_environment()
    check_package_installation()
    check_gpu_environment()
    check_xgboost()
    check_pytorch()
    check_compatibility()
    
    print_separator("æµ‹è¯•æ€»ç»“")
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("   1. å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·æ ¹æ®å»ºè®®è¿›è¡Œä¿®å¤")
    print("   2. è¿è¡Œ python train_classifier.py å¼€å§‹è®­ç»ƒ")
    print("   3. è¿è¡Œ python radar_display_qt.py å¯åŠ¨é›·è¾¾UI")

if __name__ == "__main__":
    main() 